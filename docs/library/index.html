<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-library">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Library | REASONER</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://reasoner2023.github.io/docs/library"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Library | REASONER"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://reasoner2023.github.io/docs/library"><link data-rh="true" rel="alternate" href="https://reasoner2023.github.io/docs/library" hreflang="en"><link data-rh="true" rel="alternate" href="https://reasoner2023.github.io/docs/library" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.0ae7af57.css">
<link rel="preload" href="/assets/js/runtime~main.b7150aff.js" as="script">
<link rel="preload" href="/assets/js/main.30083ea6.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="REASONER Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.png" alt="REASONER Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">REASONER</b></a><a class="navbar__item navbar__link" href="/docs/dataset">Dataset</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/library">Library</a><a class="navbar__item navbar__link" href="/docs/about">About</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/REASONER2023/reasoner2023.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Library</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2><p>Along with REASONER, we develop an explainable recommendation library. This library provides two types of widely studied explainable recommender models. The first one are feature based explainable recommender models, and the second one are the models with natural language explanations.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-obtain-the-library">How to Obtain the Library<a href="#how-to-obtain-the-library" class="hash-link" aria-label="Direct link to How to Obtain the Library" title="Direct link to How to Obtain the Library">​</a></h2><p>You can access our library through <a href="https://github.com/REASONER2023/reasoner2023.github.io/tree/main" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="model">Model<a href="#model" class="hash-link" aria-label="Direct link to Model" title="Direct link to Model">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tag-aware-models">Tag-aware models<a href="#tag-aware-models" class="hash-link" aria-label="Direct link to Tag-aware models" title="Direct link to Tag-aware models">​</a></h3><table><thead><tr><th align="center">Model</th><th align="center">Description</th><th align="center">Reference</th><th align="center">Year</th></tr></thead><tbody><tr><td align="center">EFM</td><td align="center">EFM predicts the user preferences and generates explainable recommendations based on explicit product features and user opinions from the review information.</td><td align="center"><a href="https://www.cs.cmu.edu/~glai1/papers/yongfeng-guokun-sigir14.pdf" target="_blank" rel="noopener noreferrer">Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis</a>  (Yongfeng Zhang et al.,  SIGIR2014)</td><td align="center">2014</td></tr><tr><td align="center">TriRank</td><td align="center">TriRank models the user-item-aspect ternary relation as a heterogeneous tripartite graph based on user ratings and reviews, and it devises a vertex ranking algorithm for recommendation.</td><td align="center"><a href="https://wing.comp.nus.edu.sg/wp-content/uploads/Publications/PDF/TriRank-%20Review-aware%20Explainable%20Recommendation%20by%20Modeling%20Aspects.pdf" target="_blank" rel="noopener noreferrer">TriRank: Review-aware Explainable Recommendation by Modeling Aspects</a> (Xiangnan He et al., CIKM2015)</td><td align="center">2015</td></tr><tr><td align="center">LRPPM</td><td align="center">A tensor-matrix factorization algorithm which captures the user preferences using ranking-based optimization objective over various item aspects.</td><td align="center"><a href="http://yongfeng.me/attach/sigir16-chen.pdf" target="_blank" rel="noopener noreferrer">Learning to Rank Features for Recommendation over Multiple Categories</a> (Xu Chen et al., SIGIR 2016)</td><td align="center">2016</td></tr><tr><td align="center">SULM</td><td align="center">SULM enhances recommendations by recommending not only item but also the specific aspects by using aspect-level sentiment analysis.</td><td align="center"><a href="https://www.researchgate.net/profile/Konstantin-Bauman/publication/318915371_Aspect_Based_Recommendations_Recommending_Items_with_the_Most_Valuable_Aspects_Based_on_User_Reviews/links/5f06007e92851c52d620bc9f/Aspect-Based-Recommendations-Recommending-Items-with-the-Most-Valuable-Aspects-Based-on-User-Reviews.pdf" target="_blank" rel="noopener noreferrer">Aspect Based Recommendations: Recommending Items with the Most Valuable Aspects Based on User Reviews</a>  (Konstantin Bauman et al., KDD 2017)</td><td align="center">2017</td></tr><tr><td align="center">MTER</td><td align="center">MTER is a tensor factorization method which models the task of item recommendation using a three-way tensor over the users, items and features. We omit the modeling of the opinions in the original implementation for adapting our data.</td><td align="center"><a href="https://dl.acm.org/doi/pdf/10.1145/3209978.3210010" target="_blank" rel="noopener noreferrer">Explainable Recommendation via Multi-Task Learning in Opinionated Text Data</a>  (Nan Wang et al.,  SIGIR2018)</td><td align="center">2018</td></tr><tr><td align="center">AMF</td><td align="center">AMF improves the recommendation accuracy by using the auxiliary information extracted from the user review aspects.</td><td align="center"><a href="https://yneversky.github.io/Papers/Hou2019_Article_ExplainableRecommendationWithF.pdf" target="_blank" rel="noopener noreferrer">Explainable recommendation with fusion of aspect information</a> (Yunfeng Hou et al., WWW2019)</td><td align="center">2019</td></tr><tr><td align="center">DERM-MLP</td><td align="center">DERM is a deep recommender model for jointly predicting the ratings and tags. The two tasks share the set of user/item/tag embeddings. The hidden states as well as the tag embeddings are put into different layers corresponding to the different tasks.</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">DERM-MF</td><td align="center">DERM-MF firstly obtains a hidden state based on the user/item embeddings using matrix factorization, and then the outputs are computed by a neural network.</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">DERM-C</td><td align="center">DERM-C combines matrix factorization and Multi-Layer Perceptron (MLP) to derive the hidden states, and the outputs are merged in a concatenated manner.</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">DERM-H</td><td align="center">DERM-H leverages the tags to profile the users and items, and then use the same architecture as DERM-MLP for predicting the ratings and tags.</td><td align="center">-</td><td align="center">-</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="review-aware-models">Review-aware models<a href="#review-aware-models" class="hash-link" aria-label="Direct link to Review-aware models" title="Direct link to Review-aware models">​</a></h3><table><thead><tr><th align="center">Model</th><th align="center">Description</th><th align="center">Reference</th><th align="center">Year</th></tr></thead><tbody><tr><td align="center">Att2Seq</td><td align="center">A review generation model which uses LSTM as the decoder, and output the texts directly based on the user/item IDs and rating information.</td><td align="center"><a href="https://aclanthology.org/E17-1059.pdf" target="_blank" rel="noopener noreferrer">Learning to Generate Product Reviews from Attributes</a> (Li Dong et al. ACL2017)</td><td align="center">2017</td></tr><tr><td align="center">NRT</td><td align="center">NRT simultaneously predicts the reviews and ratings based on the input user-item pair, where the two tasks share the same embedding and hidden layers.</td><td align="center"><a href="https://arxiv.org/pdf/1708.00154.pdf" target="_blank" rel="noopener noreferrer">Neural Rating Regression with Abstractive Tips Generation for Recommendation</a> (Piji Li et al, SIGIR2017)</td><td align="center">2017</td></tr><tr><td align="center">PETER</td><td align="center">PETER leverages Transformer to generate the user reviews, which is a state-of-the-art review generation model.</td><td align="center"><a href="https://arxiv.org/pdf/2105.11601.pdf" target="_blank" rel="noopener noreferrer">Personalized Transformer for Explainable Recommendation</a> (Lei Li et al. ACL2021)</td><td align="center">2021</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="framework">Framework<a href="#framework" class="hash-link" aria-label="Direct link to Framework" title="Direct link to Framework">​</a></h2><div style="text-align:center"><img loading="lazy" src="/assets/images/structure-d38f64069d50610c46b0fec5103b0e8d.png" style="width:80%" class="img_ev3q"></div><p>The structure of our library is shown in the figure above. The configuration module is the base part of the library and responsible for initializing all the parameters. We support three methods to specify the parameters, that is, the command line, parameter dictionary and configuration file. Based on the configuration module, there are four upper-layer modules:</p><ul><li><strong>Data module.</strong> This module aims to convert the raw data into the model inputs. There are two components: the first one is responsible for loading the data and building vocabularies for the user reviews. The second part aims to process the data into the formats required by the model inputs, and generate the sample batches for model optimization.</li><li><strong>Model module.</strong> This module aims to implement the explainable recommender models. There are two types of methods in our library. The first one includes the feature-based explainable recommender models, and the second one contains the models with natural language explanations. We delay the detailed introduction of these models in the next section.</li><li><strong>Trainer module.</strong> This module is leveraged to implement the training losses, such as the Bayesian Personalized Ranking (BPR) and Binary Cross Entropy (BCE). In addition, this module can also record the complete model training process.</li><li><strong>Evaluation module.</strong> This module is designed to evaluate different models, and there are three types of evaluation tasks, that is, rating prediction, top-k recommendation and review generation. Upon the above four modules, there is an execution module to run different recommendation tasks.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="4quick-start">4、Quick start<a href="#4quick-start" class="hash-link" aria-label="Direct link to 4、Quick start" title="Direct link to 4、Quick start">​</a></h2><p>Here is a quick-start example for our library. You can directly execute <em>tag_predict.py</em> or <em>review_generate.py</em> to run a feature based or natural language based model, respectively. In each of these commends, you need to specify three parameters to indicate the names of the model, dataset and configuration file, respectively.</p><p>Run feature based models:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python tag_predict.py --model</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">model name</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> --dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">dataset</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> --config</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">config_files</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Run natural language based models:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python review_generate.py --model</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">model name</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> --dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">dataset</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> --config</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">config_files</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/REASONER2023/reasoner2023.github.io/tree/main/docs/library.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#how-to-obtain-the-library" class="table-of-contents__link toc-highlight">How to Obtain the Library</a></li><li><a href="#model" class="table-of-contents__link toc-highlight">Model</a><ul><li><a href="#tag-aware-models" class="table-of-contents__link toc-highlight">Tag-aware models</a></li><li><a href="#review-aware-models" class="table-of-contents__link toc-highlight">Review-aware models</a></li></ul></li><li><a href="#framework" class="table-of-contents__link toc-highlight">Framework</a></li><li><a href="#4quick-start" class="table-of-contents__link toc-highlight">4、Quick start</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/assets/js/runtime~main.b7150aff.js"></script>
<script src="/assets/js/main.30083ea6.js"></script>
</body>
</html>